package org.dama.datasynth.runtime.spark.operators

import java.net.{URL, URLClassLoader}

import org.apache.spark.sql.SparkSession
import org.dama.datasynth.common.generators.property.PropertyGenerator
import org.dama.datasynth.executionplan.ExecutionPlan
import org.dama.datasynth.runtime.spark.SparkRuntime
import org.dama.datasynth.runtime.spark.utils.PropertyGeneratorWrapper

import scala.util.{Failure, Success}

/**
  * Created by aprat on 9/04/17.
  *
  * Operator to instantiate property generators
  */
class InstantiatePropertyGeneratorOperator {

  /**
    * Instantiates a property generator
    * @param info The execution plan node representing the property generator
    * @tparam T The type of the property generated by the instantiated property generator
    * @return The instantiated property generator
    */
  def apply[T](propertyTableName : String, info : ExecutionPlan.PropertyGenerator[T]) : PropertyGeneratorWrapper[T] = {
    val initParameters : Seq[Object] = info.initParameters.map( x => SparkRuntime.evalValueOperator(x))
                                                          .map( ref => ref.asInstanceOf[Object])
    val jarUrl = "file://"+SparkRuntime.getConfig().driverWorkspaceDir+"/temp.jar"
    val urlCL = new URLClassLoader( Array[URL]( new URL(jarUrl)),getClass.getClassLoader());
    val constructor = urlCL.loadClass(info.className).getConstructors()(0)
    val generator = constructor.newInstance(initParameters : _*).asInstanceOf[PropertyGenerator[T]]
    val rndGen = SparkRuntime.fetchRndGeneratorOperator(propertyTableName)
    val dependentPGs = info.dependentPropertyTables.map( pt => SparkRuntime.instantiatePropertyGeneratorOperator(pt.name, pt.generator))
    new PropertyGeneratorWrapper[T](generator,rndGen,dependentPGs)
  }
}
