package org.dama.datasynth.runtime.spark.operators

import java.net.{URL, URLClassLoader}

import org.apache.spark.sql.SparkSession
import org.dama.datasynth.common.generators.property.PropertyGenerator
import org.dama.datasynth.executionplan.ExecutionPlan
import org.dama.datasynth.runtime.spark.utils.PropertyGeneratorWrapper

import scala.util.{Failure, Success}

/**
  * Created by aprat on 9/04/17.
  *
  * Operator to instantiate property generators
  */
object InstantiatePropertyGeneratorOperator {

  /**
    * Instantiates a property generator
    * @param info The execution plan node representing the property generator
    * @tparam T The type of the property generated by the instantiated property generator
    * @return The instantiated property generator
    */
  def apply[T](sparkSession : SparkSession, propertyTableName : String, info : ExecutionPlan.PropertyGenerator[T]) : PropertyGeneratorWrapper[T] = {
    val initParameters : Seq[Object] = info.initParameters.map( x => EvalValueOperator(sparkSession,x)).map( ref => ref.asInstanceOf[Object])
    val urlCL = new URLClassLoader( Array[URL](new URL("file:///tmp/temp.jar")), getClass.getClassLoader());
    val constructor = urlCL.loadClass(info.className).getConstructors()(0)
    val generator = constructor.newInstance(initParameters : _*).asInstanceOf[PropertyGenerator[T]]
    val rndGen = FetchRndGeneratorOperator(propertyTableName)
    val dependentPGs = info.dependentPropertyTables.map( pt => InstantiatePropertyGeneratorOperator(sparkSession,pt.name, pt.generator))
    new PropertyGeneratorWrapper[T](generator,rndGen,dependentPGs)
  }
}
